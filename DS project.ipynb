{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f9bd13",
   "metadata": {},
   "source": [
    "The primary objective of this project is to leverage machine learning for predicting the revenues of ABB Electrification's business area. If the dataset proves suitable, an additional aim is to extend this methodology to ABB's industry counterparts.\n",
    "\n",
    "To achieve these goals, we will conduct an in-depth analysis of the following datasets:\n",
    "- Revenues CSV file for ABB and its peers (current as of Q3 2023)\n",
    "- Macroeconomic indicators from the World Economic Forum (WEF) CSV file (reflecting data as of October 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "582e2d59",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39896\\1471992875.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterp1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddde76f",
   "metadata": {},
   "source": [
    "# Revenues file - Data modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3b00b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading the dataset with Company Revenue and Profitability\n",
    "df = pd.read_csv(\"Financials v2 - Copy.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpivot the DataFrame, change column types and change the 'CIQ Formula column' values\n",
    "df = pd.melt(df, id_vars=['Ticker', 'Company name', 'Segment', 'Segment Number', 'CIQ Formula', 'Currency'], var_name='Date', value_name='Value')\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
    "df['CIQ Formula'] = df['CIQ Formula'].replace({'IQ_BUS_SEG_REV': 'Revenue', 'IQ_BUS_SEG_OPER_INC_ABS': 'Profitability', 'IQ_BUS_SEG_EBITDA_ABS': 'Profitability'})\n",
    "df = df.sort_values(by=['Ticker', 'Date'])\n",
    "\n",
    "df\n",
    "# Data types sanity-check\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many missing values are in 'Value' column. Focus on Revenues.\n",
    "zero_table = df[(df['Value'] == 0) & (df['CIQ Formula'] == 'Revenue')]\n",
    "zero_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5af47",
   "metadata": {},
   "source": [
    "Now we have confirmed that each column has been assigned the correct data type, but we've identified numerous missing values that require attention. Imputing the mean value may not be feasible due to the high prevalence of missing data. Let's explore whether Linear Regression would be a suitable approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68da2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year and month from the 'Date' column\n",
    "df['YearMonth'] = df['Date'].dt.to_period('M')\n",
    "\n",
    "# Map Year-Month to a numerical representation\n",
    "df['YearMonthNumeric'] = df['YearMonth'].apply(lambda x: x.year * 12 + x.month)\n",
    "\n",
    "# Select rows with 'Value' == 0 and 'Value' != 0\n",
    "df_missing = df[df['Value'] == 0]\n",
    "df_not_missing = df[df['Value'] != 0].copy()  # Make a copy to avoid the SettingWithCopyWarning\n",
    "\n",
    "# Create a new column combining 'Ticker', 'Currency', 'CIQ Formula', and 'Segment' for unique combinations\n",
    "df_not_missing['UniqueCombination'] = (\n",
    "    df_not_missing['Ticker'] + '_' + df_not_missing['Currency'] + '_' +\n",
    "    df_not_missing['CIQ Formula'] + '_' + df_not_missing['Segment']\n",
    ")\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over unique combinations\n",
    "for combination, group in df_not_missing.groupby('UniqueCombination'):\n",
    "    # Check if there are any samples for training\n",
    "    if len(group) > 0:\n",
    "        # Prepare data for regression\n",
    "        X_train = group[['YearMonthNumeric']].values.reshape(-1, 1)\n",
    "        y_train = group['Value'].values\n",
    "\n",
    "        # Filter the missing values based on the current combination\n",
    "        missing_filter = (\n",
    "            (df_missing['Ticker'] + '_' + df_missing['Currency'] + '_' +\n",
    "             df_missing['CIQ Formula'] + '_' + df_missing['Segment']) == combination\n",
    "        )\n",
    "        indices = df_missing.loc[missing_filter].index\n",
    "\n",
    "        # Check if there are any missing values for the current combination\n",
    "        if len(indices) > 0:\n",
    "            # Initialize the linear regression model\n",
    "            model = LinearRegression()\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict missing values\n",
    "            predicted_values = model.predict(df_missing.loc[missing_filter, ['YearMonthNumeric']].values.reshape(-1, 1))\n",
    "\n",
    "            # Update DataFrame with predicted values using indices\n",
    "            df.loc[indices, 'Value'] = predicted_values\n",
    "    else:\n",
    "        print(f\"Not enough samples for {combination}, skipping...\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are still some missing data in dataset. Lets use ABB, Electrification example\n",
    "abb_data = df[(df['Company name'] == 'ABB') & (df['CIQ Formula'] == 'Revenue') & (df['Segment'] == 'Electrification')]\n",
    "abb_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e546f86",
   "metadata": {},
   "source": [
    "# Revenues file - Drawing a chart for ABB Electrification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot chart\n",
    "abb_data = abb_data.sort_values(by='Date')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(abb_data['Date'], abb_data['Value'], linestyle='-', color='r')\n",
    "plt.title('Evolution of ABB EL revenue, USD')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue (USD)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d4d45",
   "metadata": {},
   "source": [
    "Linear regression might be not the best solution here.\n",
    "For the period from 2010 to 2015 the line it \"too flat\". Lets see it similar situtation is occuring in other company - for example Siemens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Siemens, Smart Infrastructure\n",
    "siemens_data = df[(df['Company name'] == 'Siemens') & (df['CIQ Formula'] == 'Revenue') & (df['Segment'] == 'Industrial Businesses (IB) - Smart Infrastructure') & (df['Currency'] == 'USD')]\n",
    "siemens_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01049bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "siemens_data = siemens_data.sort_values(by='Date')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(siemens_data['Date'], siemens_data['Value'], linestyle='-', color='c')\n",
    "plt.title('Evolution of Siemens SI revenue, USD')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue (USD)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5064a52c",
   "metadata": {},
   "source": [
    "The situation is even worse. Here, data is missing until 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9774eaaf",
   "metadata": {},
   "source": [
    "# Revenues file - Checking other companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb21d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by'Company Name' i 'Date' and summarize Revenues in USD\n",
    "revenue_data = df[df['CIQ Formula'] == 'Revenue']\n",
    "summed_data = revenue_data.groupby(['Company name', 'Date', 'Currency'], as_index=False)['Value'].sum()\n",
    "summed_data_usd = summed_data[summed_data['Currency'] == 'USD']\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Go through all companies\n",
    "for company in summed_data_usd['Company name'].unique():\n",
    "    company_data = summed_data_usd[summed_data_usd['Company name'] == company]\n",
    "    plt.plot(company_data['Date'], company_data['Value'], label=company, marker='o', linestyle='-')\n",
    "\n",
    "plt.title('Sum of Revenue for Each Company in USD')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sum of Revenue (USD)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left')  # Umieść legendę poza wykresem\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cfb41b",
   "metadata": {},
   "source": [
    "In summary, it's crucial to note that a comprehensive analysis is hindered by the absence of reliable pre-2018 data for certain companies, such as Wesco and Siemens. Therefore, to align with the primary objective of developing a ML model tailored to ABB Electrification, our focus will be exclusively on that specific dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9defccbb",
   "metadata": {},
   "source": [
    "# Revenues file - Applying 2028 Revenues prediction for ABB, Electrification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6d4d4b",
   "metadata": {},
   "source": [
    "Let's see how it would look like with pre 2015 data incorporated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the Revenue data for ABB, Electrification\n",
    "revenue_data = df[(df['CIQ Formula'] == 'Revenue') & (df['Segment'] == 'Electrification')]\n",
    "summed_data = revenue_data.groupby(['Company name', 'Date', 'Currency'], as_index=False)['Value'].sum()\n",
    "abb_data = summed_data[summed_data['Company name'] == 'ABB']\n",
    "end_date = '2028-12-31'\n",
    "\n",
    "def linear_regression_and_metrics(data, end_date='2028-12-31', test_size=0.2, random_state=42):\n",
    "    # Linear regression model\n",
    "    X = (data['Date'] - data['Date'].min()).dt.days.values.reshape(-1, 1)\n",
    "    y = data['Value']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Train the model on the training set\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict revenues for the entire dataset\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Generate dates up to the specified end date\n",
    "    future_dates = pd.date_range(start=data['Date'].min(), end=end_date, freq='M')\n",
    "    future_days = (future_dates - data['Date'].min()).days.values.reshape(-1, 1)\n",
    "\n",
    "    # Predict revenues for future dates\n",
    "    future_predictions = model.predict(future_days)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(data['Date'], data['Value'], label='Actual Data', color='red')\n",
    "    plt.plot(data['Date'], y_pred, label='Linear Regression', color='blue')\n",
    "    plt.plot(future_dates, future_predictions, label='Predicted Data', linestyle='dashed', color='green')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Revenue (USD)')\n",
    "    plt.title('Linear Regression and Future Revenue Prediction')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Print predicted revenues for the end date\n",
    "    end_date_prediction = model.predict([[ (pd.to_datetime(end_date) - data['Date'].min()).days ]])\n",
    "    print(f'Predicted Revenue for {end_date}: {end_date_prediction[0]:.2f} USD')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate performance metrics on the training set\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_train = sqrt(mse_train)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Mean Absolute Error (MAE) on training data: {mae_train:.2f}')\n",
    "    print(f'Mean Squared Error (MSE) on training data: {mse_train:.2f}')\n",
    "    print(f'Root Mean Squared Error (RMSE) on training data: {rmse_train:.2f}')\n",
    "    print(f'R-squared (R²) on training data: {r2_train:.4f}')\n",
    "\n",
    "# Example usage\n",
    "linear_regression_and_metrics(abb_data, end_date, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe64980",
   "metadata": {},
   "source": [
    "Let's now apply the same code, but for the dataset starting from 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2aab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only data related to Revenue, Electrification and starting from 2015\n",
    "abb_data_new = abb_data[abb_data['Date'] > '2015-01-01']\n",
    "\n",
    "# Use previously defined formula\n",
    "linear_regression_and_metrics(abb_data_new, end_date, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf602f",
   "metadata": {},
   "source": [
    "In summary, Model 1 outperforms Model 2 on the training set based on various metrics. Model 1 exhibits lower Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE), indicating better predictive accuracy. Additionally, Model 1 achieves a higher R-squared (R²) value, suggesting a stronger fit to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef998003",
   "metadata": {},
   "source": [
    "Now, let's try to create a proper dataset with new Values and Dates to see which macroeconomic inditaor might be related with revenue evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe61972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_regression_model(data, end_date):\n",
    "    # Support Vector Machine for regression model\n",
    "    X = (data['Date'] - data['Date'].min()).dt.days.values.reshape(-1, 1)\n",
    "    y = data['Value']\n",
    "\n",
    "    # Train a Support Vector Machine for regression model\n",
    "    svm_model = SVR(kernel='linear')  # You can choose other kernels like 'rbf', 'poly', etc.\n",
    "    svm_model.fit(X, y)\n",
    "\n",
    "    # Generate dates up to the specified end date\n",
    "    future_dates = pd.date_range(start=data['Date'].min(), end=end_date, freq='M')\n",
    "    future_days = (future_dates - data['Date'].min()).days.values.reshape(-1, 1)\n",
    "\n",
    "    # Predict revenues for future dates\n",
    "    future_predictions = svm_model.predict(future_days)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(data['Date'], data['Value'], label='Actual Data', color='red')\n",
    "    plt.plot(data['Date'], svm_model.predict(X), label='SVM Regression', color='blue')\n",
    "    plt.plot(future_dates, future_predictions, label='Predicted Data', linestyle='dashed', color='green')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Revenue (USD)')\n",
    "    plt.title('SVM Regression and Future Revenue Prediction')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Print predicted revenues for the end date\n",
    "    end_date_prediction = svm_model.predict([[ (pd.to_datetime(end_date) - data['Date'].min()).days ]])\n",
    "    print(f'Predicted Revenue for {end_date}: {end_date_prediction[0]:.2f} USD')\n",
    "\n",
    "    # Performance Metrics\n",
    "    y_pred_train = svm_model.predict(X)\n",
    "    mae_train = mean_absolute_error(y, y_pred_train)\n",
    "    mse_train = mean_squared_error(y, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    r2_train = r2_score(y, y_pred_train)\n",
    "\n",
    "    print(f'Mean Absolute Error (MAE) on training data: {mae_train:.2f}')\n",
    "    print(f'Mean Squared Error (MSE) on training data: {mse_train:.2f}')\n",
    "    print(f'Root Mean Squared Error (RMSE) on training data: {rmse_train:.2f}')\n",
    "    print(f'R-squared (R²) on training data: {r2_train:.4f}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "svm_regression_model(abb_data, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_model(data, end_date):\n",
    "    # XGBoost model\n",
    "    X = (data['Date'] - data['Date'].min()).dt.days.values.reshape(-1, 1)\n",
    "    y = data['Value']\n",
    "\n",
    "    # Train an XGBoost model\n",
    "    xgboost_model = xgb.XGBRegressor(objective ='reg:squarederror')  # You can adjust hyperparameters as needed\n",
    "    xgboost_model.fit(X, y)\n",
    "\n",
    "    # Generate dates up to the specified end date\n",
    "    future_dates = pd.date_range(start=data['Date'].min(), end=end_date, freq='M')\n",
    "    future_days = (future_dates - data['Date'].min()).days.values.reshape(-1, 1)\n",
    "\n",
    "    # Predict revenues for future dates\n",
    "    future_predictions = xgboost_model.predict(future_days)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(data['Date'], data['Value'], label='Actual Data', color='red')\n",
    "    plt.plot(data['Date'], xgboost_model.predict(X), label='XGBoost Regression', color='blue')\n",
    "    plt.plot(future_dates, future_predictions, label='Predicted Data', linestyle='dashed', color='green')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Revenue (USD)')\n",
    "    plt.title('XGBoost Regression and Future Revenue Prediction')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Print predicted revenues for the end date\n",
    "    end_date_prediction = xgboost_model.predict([[ (pd.to_datetime(end_date) - data['Date'].min()).days ]])\n",
    "    print(f'Predicted Revenue for {end_date}: {end_date_prediction[0]:.2f} USD')\n",
    "\n",
    "    # Performance Metrics\n",
    "    y_pred_train = xgboost_model.predict(X)\n",
    "    mae_train = mean_absolute_error(y, y_pred_train)\n",
    "    mse_train = mean_squared_error(y, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    r2_train = r2_score(y, y_pred_train)\n",
    "\n",
    "    print(f'Mean Absolute Error (MAE) on training data: {mae_train:.2f}')\n",
    "    print(f'Mean Squared Error (MSE) on training data: {mse_train:.2f}')\n",
    "    print(f'Root Mean Squared Error (RMSE) on training data: {rmse_train:.2f}')\n",
    "    print(f'R-squared (R²) on training data: {r2_train:.4f}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "xgboost_model(abb_data, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af62f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only data related to Revenue and ABB Electrification\n",
    "electrification_data = df[(df['CIQ Formula'] == 'Revenue') & (df['Company name'] == 'ABB') & (df['Segment'] == 'Electrification')]\n",
    "\n",
    "# Select data for linear regression model\n",
    "X = (electrification_data['Date'] - electrification_data['Date'].min()).dt.days.values.reshape(-1, 1)\n",
    "y = electrification_data['Value']\n",
    "\n",
    "# Linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "future_dates = pd.date_range(start=electrification_data['Date'].min(), end='2028-12-31', freq='M')\n",
    "future_days = (future_dates - electrification_data['Date'].min()).days.values.reshape(-1, 1)\n",
    "\n",
    "# Predict revenues for future dates and create a DataFrame\n",
    "future_predictions = model.predict(future_days)\n",
    "predictions_df = pd.DataFrame({'Date': future_dates, 'Comapny name': 'ABB', 'Segment': 'Electrification', 'Measure': 'Revenue', 'Value': future_predictions})\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807729d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type sanity-check\n",
    "predictions_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318dfa13",
   "metadata": {},
   "source": [
    "# Macroeconomics file - Data modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d33ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro = pd.read_csv(\"WEOOct2023all.csv\")\n",
    "macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3154e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpivot the DataFrame, delete all unnecessary columns and all NaN's. Leave dates starting from 2010\n",
    "macro = macro.drop(['WEO Country Code', 'WEO Subject Code', 'Subject Notes', 'Country/Series-specific Notes'], axis=1)\n",
    "macro = pd.melt(macro, id_vars=['ISO', 'Country', 'Subject Descriptor', 'Units', 'Scale'], var_name='Date', value_name='Value')\n",
    "macro = macro.dropna(how='all')\n",
    "macro = macro.dropna(subset=['Value'])\n",
    "macro = macro[macro['Date'] != 'Estimates Start After']\n",
    "macro = macro[macro['Date'] >= '2010']\n",
    "\n",
    "macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30257702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type sanity-check\n",
    "print(macro.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac524b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix formats and sort by ISO and Date\n",
    "macro['Date'] = pd.to_datetime(macro['Date'], errors='coerce')\n",
    "macro['Value'] = pd.to_numeric(macro['Value'], errors='coerce')\n",
    "macro = macro.sort_values(by=['ISO', 'Date'])\n",
    "\n",
    "macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate Units\n",
    "unique_units = macro['Units'].unique()\n",
    "unique_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f3df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary Units\n",
    "values_to_remove = ['National currency', 'Percent change','Purchasing power parity; international dollars', 'Index',\n",
    "       'Purchasing power parity; 2017 international dollar', 'Percent',\n",
    "       'National currency per current international dollar',\n",
    "       'Percent of GDP', 'Percent of total labor force', 'Percent of potential GDP']\n",
    "macro = macro[~macro['Units'].isin(values_to_remove)]\n",
    "macro = macro.dropna(subset=['Value'])\n",
    "\n",
    "macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66912705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete more unnecessary columns\n",
    "macro = macro.drop(['ISO', 'Units', 'Scale'], axis=1)\n",
    "macro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b6db2",
   "metadata": {},
   "source": [
    "Now the dataset with macroeconomic indicators contains only convinient stuff. Next step is to pivot measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ebc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table and reset index\n",
    "pivot_macro = macro.pivot(index=['Country', 'Date'], columns='Subject Descriptor', values='Value').reset_index()\n",
    "pivot_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d114278",
   "metadata": {},
   "source": [
    "Column \"Employment\" seems to be empty - let's drop it too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete 'Employment' column\n",
    "pivot_macro = pivot_macro.drop(['Employment'], axis=1)\n",
    "pivot_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabfd8f7",
   "metadata": {},
   "source": [
    "This dataset is almost ready to be merged with the first one. There are only 2 additional columns missing. Since we are focuing on ABB Electrification this time, I will add these values as strings for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two columns\n",
    "pivot_macro['Comapny name'] = 'ABB'\n",
    "pivot_macro['Segment'] = 'Electrification'\n",
    "pivot_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafffde",
   "metadata": {},
   "source": [
    "Let's take another look at database with ABB EL revenues to see if we can merge it with new Macro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dbc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00987080",
   "metadata": {},
   "source": [
    "Once we try to merge these two columns, there might be an issue with Date column. Macro database is showing full year data, while predictions df is quarterly based. Let's change this column to show full year in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'Date' column to show year only\n",
    "pivot_macro['Date'] = pivot_macro['Date'].dt.year\n",
    "pivot_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9da2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'Date' column to show year only and group values to show total for full year\n",
    "predictions_df['Date'] = predictions_df['Date'].dt.year\n",
    "annual_sum = predictions_df.groupby(['Comapny name', 'Segment', 'Measure', 'Date'])['Value'].sum().reset_index()\n",
    "annual_sum = annual_sum.drop(['Measure'], axis=1)\n",
    "annual_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ec690a",
   "metadata": {},
   "source": [
    "Now both datasets are ready to consolidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39efe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'annual_sum' and 'pivot_macro'. Drop NaNs in 'Value' column\n",
    "merged_df = pd.merge(annual_sum, pivot_macro, on=['Comapny name', 'Segment', 'Date'], how='outer')\n",
    "merged_df = merged_df.dropna(subset=['Value'])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b3280",
   "metadata": {},
   "source": [
    "# Applying Random Forest model to merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = merged_df[['Date', 'Current account balance', 'Gross domestic product per capita, current prices', 'Gross domestic product, current prices', 'Population']]\n",
    "y = merged_df['Value']\n",
    "\n",
    "# Impute missing values using the mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Create and train a Random Forest model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_imputed, y)\n",
    "results_df = pd.DataFrame(columns=['Country', 'Mean Squared Error', 'Current account balance Importance Check', 'GDP per capita Importance Check', 'GDP Importance Check', 'Population Importance Check', 'Population Value'])\n",
    "\n",
    "# Assign feature importance values for each country\n",
    "for country in merged_df['Country'].unique():\n",
    "    country_index = merged_df['Country'] == country\n",
    "    country_mse = mean_squared_error(y[country_index], rf_model.predict(X_imputed[country_index]))\n",
    "    \n",
    "    # Train a new model for each country to get feature importances specific to that country\n",
    "    country_rf_model = RandomForestRegressor()\n",
    "    country_rf_model.fit(X_imputed[country_index], y[country_index])\n",
    "    \n",
    "    country_result = {\n",
    "        'Country': country,\n",
    "        'Mean Squared Error': country_mse,\n",
    "        'Current account balance Importance Check': country_rf_model.feature_importances_[0],\n",
    "        'GDP per capita Importance Check': country_rf_model.feature_importances_[1],\n",
    "        'GDP Importance Check': country_rf_model.feature_importances_[2],\n",
    "        'Population Importance Check': country_rf_model.feature_importances_[3],\n",
    "        'Population Value': X.loc[country_index, 'Population'].iloc[0]\n",
    "    }\n",
    "    \n",
    "    results_df = pd.concat([results_df, pd.DataFrame([country_result])], ignore_index=True)\n",
    "\n",
    "# Sort the results by Population Value in descending order\n",
    "results_df = results_df.sort_values(by='Population Value', ascending=False)\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
